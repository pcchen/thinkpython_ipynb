{
 "metadata": {
  "name": "",
  "signature": "sha256:2c18ad3b8360de20c25fcc043d642523e8e8253d27f447334b57986e12494cf0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# License\n",
      "\n",
      "This IPython Notebook is released under the [Creative Commons Attribution-NonCommercial 3.0 Unported License](http://creativecommons.org/licenses/by-nc/3.0/)\n",
      "\n",
      "This IPython Notebook is based on [Think Python: How to Think Like a Computer Scientist](http://www.greenteapress.com/thinkpython/) by Allen B. Downey. It is available under the [Creative Commons Attribution-NonCommercial 3.0 Unported License](http://creativecommons.org/licenses/by-nc/3.0/)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "****"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Chapter 13  Case study: data structure selection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "****"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 13.1  Word frequency analysis\n",
      "\n",
      "As usual, you should at least attempt the following exercises before you read my solutions.\n",
      "\n",
      "### Exercise 13.1  \n",
      "Write a program that reads a file, breaks each line into words, strips whitespace and punctuation from the words, and converts them to lowercase.\n",
      "\n",
      "Hint: The string module provides strings named whitespace, which contains space, tab, newline, etc., and punctuation which contains the punctuation characters. Let\u2019s see if we can make Python swear:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import string\n",
      "print string.punctuation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Also, you might consider using the string methods `strip`, `replace` and `translate`.\n",
      "\n",
      "### Exercise 13.2  \n",
      "\n",
      "Go to Project Gutenberg (http://gutenberg.org) and download your favorite out-of-copyright book in plain text format.\n",
      "Modify your program from the previous exercise to read the book you downloaded, skip over the header information at the beginning of the file, and process the rest of the words as before.\n",
      "\n",
      "Then modify the program to count the total number of words in the book, and the number of times each word is used.\n",
      "\n",
      "Print the number of different words used in the book. Compare different books by different authors, written in different eras. Which author uses the most extensive vocabulary?\n",
      "\n",
      "### Exercise 13.3  \n",
      "\n",
      "Modify the program from the previous exercise to print the 20 most frequently-used words in the book.\n",
      "\n",
      "### Exercise 13.4  \n",
      "\n",
      "Modify the previous program to read a word list (see Section 9.1) and then print all the words in the book that are not in the word list. How many of them are typos? How many of them are common words that should be in the word list, and how many of them are really obscure?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "****"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 13.2  Random numbers\n",
      "\n",
      "Given the same inputs, most computer programs generate the same outputs every time, so they are said to be **deterministic**. Determinism is usually a good thing, since we expect the same calculation to yield the same result. For some applications, though, we want the computer to be unpredictable. Games are an obvious example, but there are more.\n",
      "\n",
      "Making a program truly nondeterministic turns out to be not so easy, but there are ways to make it at least seem nondeterministic. One of them is to use algorithms that generate **pseudorandom** numbers. Pseudorandom numbers are not truly random because they are generated by a deterministic computation, but just by looking at the numbers it is all but impossible to distinguish them from random.\n",
      "\n",
      "The random module provides functions that generate pseudorandom numbers (which I will simply call \u201crandom\u201d from here on).\n",
      "\n",
      "The function random returns a random float between 0.0 and 1.0 (including 0.0 but not 1.0). Each time you call random, you get the next number in a long series. To see a sample, run this loop:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "\n",
      "for i in range(10):\n",
      "    x = random.random()\n",
      "    print x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.976742009402\n",
        "0.00195767816363\n",
        "0.404741004913\n",
        "0.552952973222\n",
        "0.374121820855\n",
        "0.337832669595\n",
        "0.653378920173\n",
        "0.680077197472\n",
        "0.388658945937\n",
        "0.831137935142\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function `randint` takes parameters `low` and `high` and returns an integer between `low` and `high` (including both)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print random.randint(5, 10)\n",
      "print random.randint(5, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8\n",
        "8\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To choose an element from a sequence at random, you can use `choice`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = [1, 2, 3]\n",
      "print random.choice(t)\n",
      "print random.choice(t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\n",
        "2\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The random module also provides functions to generate random values from continuous distributions including Gaussian, exponential, gamma, and a few more."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "****"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 13.5  \n",
      "\n",
      "Write a function named `choose_from_hist` that takes a histogram as defined in Section 11.1 and returns a random value from the histogram, chosen with probability in proportion to frequency. For example, for this histogram:\n",
      "\n",
      "```\n",
      "t = ['a', 'a', 'b']\n",
      "hist = histogram(t)\n",
      "print hist\n",
      "{'a': 2, 'b': 1}\n",
      "```\n",
      "\n",
      "your function should return \u2019a\u2019 with probability 2/3 and \u2019b\u2019 with probability 1/3."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "****"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 13.3  Word histogram\n",
      "\n",
      "\n",
      "You should attempt the previous exercises before you go on. You can download my solution from http://thinkpython.com/code/analyze_book.py. You will also need http://www.greenteapress.com/thinkpython/code/emma.txt.\n",
      "\n",
      "Here is a program that reads a file and builds a histogram of the words in the file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import string\n",
      "\n",
      "def process_file(filename):\n",
      "    hist = dict()\n",
      "    fp = open(filename)\n",
      "    for line in fp:\n",
      "        process_line(line, hist)\n",
      "    return hist\n",
      "\n",
      "def process_line(line, hist):\n",
      "    line = line.replace('-', ' ')\n",
      "    \n",
      "    for word in line.split():\n",
      "        word = word.strip(string.punctuation + string.whitespace)\n",
      "        word = word.lower()\n",
      "\n",
      "        hist[word] = hist.get(word, 0) + 1\n",
      "\n",
      "hist = process_file('emma.txt')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This program reads `emma.txt`, which contains the text of Emma by Jane Austen."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`process_file` loops through the lines of the file, passing them one at a time to `process_line`. The histogram `hist` is being used as an accumulator.\n",
      "\n",
      "`process_line` uses the `string` method replace to replace hyphens with spaces before using `split` to break the line into a list of strings. It traverses the list of words and uses `strip` and `lower` to remove punctuation and convert to lower case. (It is a shorthand to say that strings are \u201cconverted;\u201d remember that string are immutable, so methods like strip and lower return new strings.)\n",
      "\n",
      "Finally, `process_line` updates the histogram by creating a new item or incrementing an existing one.\n",
      "\n",
      "To count the total number of words in the file, we can add up the frequencies in the histogram:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def total_words(hist):\n",
      "    return sum(hist.values())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The number of different words is just the number of items in the dictionary:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def different_words(hist):\n",
      "    return len(hist)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is some code to print the results:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Total number of words:', total_words(hist)\n",
      "print 'Number of different words:', different_words(hist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total number of words: 162742\n",
        "Number of different words: 7460\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "****"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 13.4  Most common words\n",
      "\n",
      "To find the most common words, we can apply the DSU pattern; `most_common` takes a histogram and returns a list of word-frequency tuples, sorted in reverse order by frequency:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def most_common(hist):\n",
      "    t = []\n",
      "    for key, value in hist.items():\n",
      "        t.append((value, key))\n",
      "\n",
      "    t.sort(reverse=True)\n",
      "    return t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is a loop that prints the ten most common words:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = most_common(hist)\n",
      "print 'The most common words are:'\n",
      "for freq, word in t[0:10]:\n",
      "    print word, '\\t', freq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The most common words are:\n",
        "to \t5295\n",
        "the \t5266\n",
        "and \t4931\n",
        "of \t4339\n",
        "i \t3191\n",
        "a \t3155\n",
        "it \t2546\n",
        "her \t2483\n",
        "was \t2400\n",
        "she \t2364\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "****"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 13.5  Optional parameters\n",
      "\n",
      "We have seen built-in functions and methods that take a variable number of arguments. It is possible to write user-defined functions with optional arguments, too. For example, here is a function that prints the most common words in a histogram"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_most_common(hist, num=10):\n",
      "    t = most_common(hist)\n",
      "    print 'The most common words are:'\n",
      "    for freq, word in t[:num]:\n",
      "        print word, '\\t', freq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first parameter is required; the second is optional. The default value of `num` is 10."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you only provide one argument:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_most_common(hist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The most common words are:\n",
        "to \t5295\n",
        "the \t5266\n",
        "and \t4931\n",
        "of \t4339\n",
        "i \t3191\n",
        "a \t3155\n",
        "it \t2546\n",
        "her \t2483\n",
        "was \t2400\n",
        "she \t2364\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`num` gets the default value. If you provide two arguments:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_most_common(hist, 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The most common words are:\n",
        "to \t5295\n",
        "the \t5266\n",
        "and \t4931\n",
        "of \t4339\n",
        "i \t3191\n",
        "a \t3155\n",
        "it \t2546\n",
        "her \t2483\n",
        "was \t2400\n",
        "she \t2364\n",
        "in \t2199\n",
        "not \t2161\n",
        "you \t2053\n",
        "be \t1987\n",
        "he \t1811\n",
        "that \t1809\n",
        "had \t1626\n",
        "but \t1446\n",
        "as \t1443\n",
        "for \t1371\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`num` gets the value of the argument instead. In other words, the optional argument **overrides** the default value.\n",
      "\n",
      "If a function has both required and optional parameters, all the required parameters have to come first, followed by the optional ones."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "****"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 13.6  Dictionary subtraction\n",
      "\n",
      "Finding the words from the book that are not in the word list from `words.txt` is a problem you might recognize as set subtraction; that is, we want to find all the words from one set (the words in the book) that are not in another set (the words in the list).\n",
      "\n",
      "`subtract` takes dictionaries `d1` and `d2` and returns a new dictionary that contains all the keys from `d1` that are not in `d2`. Since we don\u2019t really care about the values, we set them all to `None`.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def subtract(d1, d2):\n",
      "    res = dict()\n",
      "    for key in d1:\n",
      "        if key not in d2:\n",
      "            res[key] = None\n",
      "    return res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To find the words in the book that are not in `words.txt`, we can use `process_file` to build a histogram for `words.txt`, and then subtract:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = process_file('words.txt')\n",
      "diff = subtract(hist, words)\n",
      "\n",
      "print \"The words in the book that aren't in the word list are:\"\n",
      "for word in diff.keys():\n",
      "    print word,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The words in the book that aren't in the word list are:\n",
        " rencontre genlis jane's blanche woodhouses disingenuousness friend's venice apartment talkativeness jeffereys neighbours tm westons undistinguishing housebreaking puppyism controul hannah inconsideration hodges isabella rationality tupmans 24th recollected daughter's asparagus ceaseless michael wakefield p xxxxx10x.xxx week's mutterings yesterday's harriet unexceptionably fairfax dir mget dexterity designedly tel their's solicitously honourably isabella's honourable augusta 7th inebriety e.'s penetrated emma's elton richard mark's novitiate portionless soothings adversary's unmirthful xvii milmans mcimail etexts embrocation scepticism christian mistress's v favourably emma10.txt behaviour favourable etext/articles november b substance index200.gut indiscreetly unobjectionable k 30 dublin penetrating person's paradings i'd acquittal john's outstepped frank's complimenter day's churchill wonderings saunders knightley's vii clara niece's hyperbolical privately sympathise compuserve sister's end*the patriae particularity unostentatious flatterers agreeably etext92 etext93 world's complaisant cultivation fragrance delightfully bates's incommoded brunswick unaccountable uncle's highbury pointedly latter's nephew's 90 iii tunbridge 1994 ford's ibc ult mr il enscombe deservedly gentlemen's december newsletters unpretending greatcoat unequalled 10,000 promptitude o emma10a.txt larkins influenced king's 1 sunday hesitatingly sauciness bickerton chusing beaufet elizabeth impartial cromer michaelmas your@login a hawkins's wiltshire churchills green's endeavoured june st groundless that's don't hypertext london comtesse unsullied broadway irksomeness wife's admirably 20 secresy treachery unprovided discourse yorkshire admirable non transcribing surry tranquillised unfeignedly humourist february doubtingly martin's january betweens l delightful stomacher grandmother's confederates england another's slightingly discomposed remembrance saturday neighbourhood smith's deedily unexceptionable robert woodhouse emma10.zip internet one's heroine's complimented aladdin's friday shepherd's unconvinced caro ebcdic people's collation philip man_'s placidity woman's grandpapa bragges w larkins's disclaimer do's baker's father's email grandpapas xv george donwell solitarily xii heartedness an't otways 2 xiv xix alderneys misunderstood unpardonably pressingly unsuspicious gentlemanlike tremblings apologise knightley wingfield's mantelpiece undiscerned july unmentioned here's exultingly blameable 10 etexts*ver.04.29.93*end exultation morning's submissively unsentimental mother's swisserland new.gut body's teazed insignificance pre attmail graham's craig incommoding philippics humouredly etext/etext91 woodhouse's etext silversmith unsuitable d'ye pianoforte scotland patroness churchwardens rumination transcribed hour's fairfax's appellation fastidious familiarise harriet's aunt's confidantes fortnight's gutenberg/ibc ballroom's reanimation pembroke tautology blockhead her's mrs charitable engagement's hindrance unimpeded bitnet charles mama's manchester endeavour man's month's richmond prosings criticising foolishly caroline heartfelt cellery recollecting champaign wallis companionably mickleham penetrate mrcnext.cso.uiuc.edu dr desirableness hymen's underbred randalls illiberal behindhand hartfield housekeeper's your's disapprobation 18 x buyings unfrequently smallridge proportionably delicately braithwaites expediency encourager waverings suckling's index100.gut smallridge's outwardly excusable goddard tupman master's 5093 southward xvi benedictine 3 injustice law's etexts**start untainted smilingly disagreeableness garrick's untouched clayton york untowardly reprobating aggrandise observable c f goodnatured inseparably sympathiser disengage etc s chuses doatingly successless login can't complacently churchill'd perrys authorised tuesday haberdasher's cd 60 undoubting churchill's connexion 254 hawkins bragge holyhead houseroom sufferable composedly aimable ireland lady's ungallant selina mitchell's what's elton's neighbour arrowroot stilton coxe gentleman's apologised hughes 61825 sweetbread bateses henry's disclaimers unpersuadable n wallises morrow's viii grandmama's etext/etext93 nobody's unexampled ix weston's manoeuvring vi broadwood randall's iv ii splendour destin'd serle unreserved ascii james's companionableness april barnes bella windsor broadwood's unconcern unperceived theodore wink'd d'almane sposo baly 100,000,000=trillion otway solemnity i farmer's neptune 1971 quicksighted conversable weymouth goddard's grandmama inquietudes 212 connexions kramer ocr harmonise birmingham clifton campbell unceremoniousness ostler's electronically suitableness bella's men's hetty butcher's ma'am greensward dixon 31 infant's unfastidious tongue's constitutions emma11.txt campbells recantation chuse valetudinarian emma d night's amiableness arthur stept james amor xviii cramer italian irresistibly apartments inferiorities girl's collectedly experienced 28th cowper shan't ungracious 2782 o'clock langham wingfield two's shakespeare adventuring 23rd anne unexpensively christmas son's unsuccessfully ungraciously thing's unbleached undesignedly unseasonableness william's entertainingly where's start**the dixons campbell's butler's complaisance recollect hart@uiucvmd prepossession sanguinely brown's improvidently knightleys project's merchantability encumbrance unfavourable eltons imaginist fancifulness catherine uninterruptedly instant's austen commandingly endeavours print!**for endeavouring crossness goodhumoured unsuspected stimulative husband's minute's astley's unpolished unexamined discordancies disengaged child's perry's 26th feelingly fidgetiness selina's cole's se'nnight october wretchedly outree acquirements adair unreserve cobham brother's 72600.2026@compuserve.com irish taylor abruptness remembrances lieut 158 kingston al unmodulated weston dixon's xiii ing unpermitted hazle adelaide undesigned dorking administered moment's illinois uncouthness visitings hartfield's taylor's monday ftp favourite gradations m bragge's william gutenberg hart@vmd.cso.uiuc.edu richardson twelvemonth persuadable e tete instrument's 2002 2001 d'ostalis nash abdy's cox's 8th\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some of these words are names and possessives. Others, like \u201crencontre,\u201d are no longer in common use. But a few are common words that should really be in the list!\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "****"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 13.6\n",
      "\n",
      "Python provides a data structure called set that provides many common set operations. Read the documentation at http://docs.python.org/2/library/stdtypes.html#types-set and write a program that uses set subtraction to find words in the book that are not in the word list. Solution: http://thinkpython.com/code/analyze_book2.py."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "****"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 13.7  Random words\n",
      "\n",
      "To choose a random word from the histogram, the simplest algorithm is to build a list with multiple copies of each word, according to the observed frequency, and then choose from the list:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def random_word(h):\n",
      "    t = []\n",
      "    for word, freq in h.items():\n",
      "        t.extend([word] * freq)\n",
      "\n",
      "    return random.choice(t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The expression `[word] * freq` creates a list with `freq` copies of the string word. The `extend` method is similar to `append` except that the argument is a sequence."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "****"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 13.8  Markov analysis\n",
      "\n",
      "If you choose words from the book at random, you can get a sense of the vocabulary, you probably won\u2019t get a sentence:\n",
      "\n",
      "``\n",
      "this the small regard harriet which knightley's it most things\n",
      "``\n",
      "\n",
      "A series of random words seldom makes sense because there is no relationship between successive words. For example, in a real sentence you would expect an article like \u201cthe\u201d to be followed by an adjective or a noun, and probably not a verb or adverb.\n",
      "One way to measure these kinds of relationships is Markov analysis, which characterizes, for a given sequence of words, the probability of the word that comes next. For example, the song *Eric, the Half a Bee* begins:\n",
      "\n",
      "```\n",
      "Half a bee, philosophically,\n",
      "Must, ipso facto, half not be.\n",
      "But half the bee has got to be\n",
      "Vis a vis, its entity. D\u2019you see?\n",
      "\n",
      "But can a bee be said to be\n",
      "Or not to be an entire bee\n",
      "When half the bee is not a bee\n",
      "Due to some ancient injury?\n",
      "```\n",
      "\n",
      "In this text, the phrase \u201chalf the\u201d is always followed by the word \u201cbee,\u201d but the phrase \u201cthe bee\u201d might be followed by either \u201chas\u201d or \u201cis\u201d."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}